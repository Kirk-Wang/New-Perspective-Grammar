Now that we know we've hit a bottleneck with the worker,

we have to look at the other parts of this app to see if

现在我们知道我们已经在 worker 上遇到了瓶颈，
我们必须查看这个应用程序的其他部分，看看它们是否是瓶颈。

they're the bottleneck. If you had better instrumentation

in your apps, which I hope you do, because ours has none.

如果你在你的应用程序中有更好的仪表，我希望你有，因为我们没有。

You would have cool applications like the ones listed here,

or other projects, that would give you more data about the

metrics from each part of your app.

你会有一些很酷的应用程序，
比如这里列出的那些，或者其他项目，
它们会给你更多关于应用程序每个部分的指标的数据。

That's really important in distributed apps because you

have them all spread over the place.

这在分布式应用中非常重要，因为你把它们分散在不同的地方。

So, the network is part of the app.

所以，网络是应用程序的一部分。

Which means you to start tracking network performance

of the different parts more importantly. You can read that

all over the Internet about microservices and the

challenges of monitoring and troubleshooting microservices.

这意味着你开始跟踪网络性能的不同部分更加重要。
你可以在互联网上读到关于微服务以及监控和故障排除微服务的挑战。
* all over 到处，遍及; 全部完结

We can use a couple of simple utilities here to get basic

performance out of this app.

我们可以使用一些简单的实用工具来获得这个应用程序的基本性能。

One of those is a httping.

其中之一就是 httping。

That's a cool utility that I like to use.

我喜欢用这个很酷的工具。

It's the combination of ping for HTTP.

它是 HTTP 的 ping 的组合。

That's really all it is.

就是这样。

We're going to run it from the command line just like we

would a ping utility, but it's going to use the

HTTP protocol to connect to these applications.

我们将从命令行运行它，就像使用 ping 实用程序一样，
但它将使用 HTTP 协议连接到这些应用程序。

We can't use it on the worker because that doesn't have an

endpoint. But, we can use it on rng and the hasher.

我们不能在 worker 上使用它，因为它没有端点。
但是，我们可以在 rng 和 hasher 上使用它。

First up, let's get back to our command line.

首先，让我们回到命令行。

We're going to take the cluster IP,

and we could just copy and paste them, but we're going to

use the same bash one liner here that sets an

environment variable to the IP address of each services

cluster IP.

我们将使用集群 IP，我们可以复制并粘贴它们，
但是我们将使用相同的 bash 代码，
它将环境变量设置
为每个服务集群 IP 的 IP 地址。

So, instead of typing these out, I'm just going

to copy and paste them. We've done this command before,

and we're going to use those to save us some time.

所以，我不把这些打出来，
我只是复制和粘贴它们。
我们以前做过这个命令，
我们将使用它们来节省一些时间。

That way, we can use these different

hasher and rng IP addresses in various commands.

这样，我们可以在各种命令中使用这些不同的 hasher 和 rng IP 地址。

Then, we're going to use the shpod utility

to get into our cluster since these things don't have node

然后，我们将使用 shpod 实用程序进入我们的集群，因为这些东西没有节点端口。

ports. We need to be in the cluster unless you're on

a Linux host where you have native access to these IP

我们需要在集群中，除非您是在Linux主机上，您可以对这些IP地址进行本地访问。

addresses. The first two commands here, if you're on Mac

or Windows with Docker Desktop, or other tools,

you can do this, kubectl apply like we showed earlier.

这里的前两个命令，
如果你在 Mac 或 Windows 上使用 Docker Desktop 或其他工具，
你可以这样做，kubectl apply，就像我们之前展示的那样。

Then you can also attach to that so that we get a

shell in our cluster.

然后你也可以附加到它，这样我们就可以在集群中得到一个shell。

This shell will also have a httping installed.

这个 shell 还将安装 httping。

You can get httping on Linux like with APT,

get it on a Mac with Brew.

你可以用 APT 在 Linux 上获得 http，用 Brew 在 Mac 上获得。

The last I looked you couldn't get it natively on Windows,

but that's why we have this shpod.

我最后一次看的时候，你无法在 Windows 上获得它，
但这就是为什么我们有这个 shpod。

All right. I ran the kubectl apply to create my

pod, or sh-tools.

好吧。我运行了 kubectl apply 来创建我的 pod，或者 sh-tools。

Now I'm in it. It should look like this to you as well,

现在我参与其中了。在您的命令行中，也应该是这样的。

where you have a command line. If you don't have that

colorful command line, just hit enter and you should see

如果您没有彩色的命令行，只需按回车，您应该可以看到它。

it. We're going to run httping here,

and we're going to use the environment variables, but

you're going to need to get those environment variables in

to the shpod if you need that.

我们将在这里运行 httping，
我们将使用环境变量，
但你需要把这些环境变量放到 shpod 中，
如果你需要的话。

You might need to go back a slide now that you're in shpod.

你现在在 shpod，可能需要回到幻灯片上。

Copy those two lines out, run them again inside

that pod.

把这两行复制出来，在那个 pod 里运行。

Then, we're going to go back to those httping commands.

然后，我们将回到那些 httping 命令。

All right. First command is httping -c

3 with

the hasher.

好吧。第一个命令是 httping-c 3 具有 hasher。

Of course, your IP address is going to be different than

mine. You can see here it just did three

pings to the HTTP protocol.

当然，你的 IP 地址和我的不同。
可以看到，这里它只对 HTTP 协议进行了三次 ping。

You can see that the important part I'm looking at here is

the response time.

你可以看到我在这里看到的重要部分是响应时间。

We've got six milliseconds.

我们有 6 毫秒。

That's pretty pretty standard for a small little web

service. That's pretty quick.

这对于小型 web 服务来说是非常标准的。这是非常快速。

Nothing to complain about there.

Let's look at the rng.

We have quite a different return

value. Look at those milliseconds. That's almost a full

second in response time.

That definitely seems to be suspect.

I know what's wrong with this app.

You don't know that yet, but obviously we put something in

here that's deliberate.

This isn't a true troubleshooting scenario.

It is a hasty conclusion here.

That hasty conclusion is well, the rng seems to

be the bottleneck because we expect it to be faster than

that. Maybe because a random number

generator generates random numbers, we need to

use multiple servers because we're using random

number generators. On Linux, there's this thing called

dev/random or dev/urandom down at the bottom.

You can geek out on the Internet if you're all interested

in random numbers and how Linux makes them.

We can make up an imaginary story here that I'm going to

say is the reason this is slow is because we don't

have enough entropy on our machine.

We're going to need to scale this out.

Because we're learning Kubernetes and this is just the

beginning, we only have a single-server setup.

If you've gone ahead and deployed a multi-server setup,

then good for you. This next section will make a little

more sense. What we're going to do right now is we're

going to use a new resource type in Kubernetes

that is designed to scale out across multiple

nodes. We won't be able to do that on a single-node

cluster. It'll work. It just won't scale to many different

nodes.

I will explain it along the way.

Trust me, it's going to make sense.

But later on in the course, we'll have the opportunity to

use the Cloud, or some other resources you have, to make a

multi-node setup. Let's get started on the next type of

resource, DaemonSets.