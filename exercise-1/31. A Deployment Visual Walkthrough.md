What's really happening when we do that

kubectl run command?

当我们执行 kubectl 运行命令时，到底发生了什么?

I mean, we run it, and then we do a get all and we see a

bunch of things. But, how is that stuff getting to

the point of a container getting started?

我的意思是，我们运行它，
然后我们做一个 get all，我们看到一堆东西。
但是，这些东西是如何到达容器的起点的呢？

There's actually a lot of steps.

实际上有很多步骤。

You could write an entire short story around

how this happens, but sometimes visualizations

are a little easier. Let's walk through this, each

action at a time, from the time you type the

command in the CLI, all the way through to

how it goes into a container starting.

你可以写一个完整的短篇故事来描述这是如何发生的，
但是有时候可视化会更容易一些。
让我们一次一个动作地了解一下，
从在 CLI 中键入命令开始，
一直到它如何开始进入容器。
* walk through 走过；轻松地初排；草率地处理
* entire adj.全部的;整个的;完全的
* all the way 一路上；自始至终; 一直
* at a time 依次; 每次

Imagine we have this control plane.

假设我们有一个控制平面。

We don't know whether it's one master server or a bunch of

them. We just have the proper parts that we need.

我们不知道它是一个主服务器还是一堆主服务器。我们只需要合适的零件。
* have the proper 有适当的

We have the etcd, the API.

我们有 etcd 和 API。

We have the scheduler, the controller manager.

我们有调度程序，控制器管理器。

Then in this case, we're going to have two worker nodes,

right.

在这种情况下，我们将有两个工作节点，对吧。

They're both running the kubelet and the kube-proxy, maybe

a networking overlay.

他们都在运行 kubelet 和 kube-proxy，可能是一个 networking overlay。

But, the point here is these are the minimum components to

get started. Imagine you're on your machine.

但是，这里的要点是，这些是开始使用的最小组件。想象你在你的机器上。

It could be remote. It could be on the server itself.

它可能很遥远。它可能在服务器本身。
* remote 
  * adj. 遥远的；偏僻的；疏远的
  * n. 远程

You type a kubectl run command

of web. We're going to call it web.

输入一个 kubectl 运行 web 命令。我们称它为 web。

We're going to use the Nginx image to create

three web servers as three replicas.

我们将使用 Nginx 镜像创建三个 web 服务器作为三个副本。

When you do that, you're talking with your kubectl

to the API directly.

当你这样做时，你正在使用你的 kubectl 与 API 直接通信。

That's how the command gets sent.

这就是发送命令的方式。

It's talking to the API.

它在和 API 通信。

That API server will then store

a new object for this resource, the deployment resource,

based on that command.

然后，该 API 服务器将基于该命令为该资源（deployment resource）存储一个新对象。

It knows that you're essentially asking for

a deployment at that point, and it's storing it in the etcd

database.

它知道您实际上是在请求部署，并将其存储在etcd数据库中。
* at that point 就在那时

And, cool.

You get back a little notification that says we're created.

你会得到一个小通知，说我们被创建了。

Job well done.

工作做得好。

The difference is, though, is that it's not really done.

不过，不同的是，这并没有真正完成。
* though 
  * conj. 虽然，尽管
  * adv. 虽然；不过；然而

This all happened super fast in just a couple of seconds,

but you get returned a result.

这一切在几秒钟内发生得非常快，但你得到了一个结果。

That doesn't mean the container is running.

这并不意味着容器正在运行。

It just means that the object for this resource

was stored in the database successfully.

这意味着此资源的对象已成功存储在数据库中。

What happens next?

接下来会发生什么？

Well, this controller manager does exactly what it says.

这个控制器管理器完全按照它说的做。

It is a management API that sits

there with a bunch of different controllers for resources,

and it's constantly checking to see what the database

has for it. In this case, it's going to ask the API

server, hey, do you have any new controllers

that I'm not aware of? It will find that there's a

deployment resource available.

它是一个管理 API，
它与一堆不同的资源控制器放在一起，
它不断地检查数据库有什么资源。
在这种情况下，它会问API服务器，
你有我不知道的新控制器吗?
它将发现有可用的部署资源。
* constantly adv.始终;一直;重复不断地

Cool. It will then create the resource

that the spec, for that deployment, requests.

酷。然后，它将创建那个规范的资源，针对 deployment, 请求

That deployment is saying, I would like a ReplicaSet, and

here is the spec for the ReplicaSet.

该部署是说，我想要一个副本集，这里是副本集的规范。

The controller manager does that.

控制器管理器会这样做。

It writes another object record to the etcd database,

and then that transaction is over.

它将另一个对象记录写入 etcd 数据库，然后该事务结束。

Then we wait, maybe a few microseconds,

maybe a few nanoseconds.

然后我们等待，也许几微秒，也许几纳秒。

Then, the controller manager is requesting again.

然后，控制器管理器再次发出请求。

Then we wait.

然后我们等待。

This is actually the controller manager polling interval

that you can set up. If you get really into production

clusters, you can change that, but it's less than a second.

这实际上是你可以设置的控制器管理器轮询间隔。
如果你真的进入了生产集群，
你可以改变它，但它不到一秒。

It's going to check again, and this time, it will notice a

new resource object.

它将再次检查，这一次，它将注意到一个新的资源对象。

All of the ReplicaSet.

所有的复制集。

Cool. It now has more work to do, so it will

then say, OK. This ReplicaSet is requesting three

pods with this spec.

很酷。它现在有更多的工作要做，
所以它会说，好。
这个复制集请求三个具有这个规范的 pod。

So, I will create three, identical

pod specs inside the etcd database

with a status of pending.

Then it's done.

On the scheduler side of things, the scheduler also

pulls the API every so often.

This is hitting the API server and saying,

are there any new pods that I need

to schedule somewhere in this cluster?

It finds three pods pending, which indicates

that they are not yet scheduled for a particular node.

So, the scheduler runs its algorithm and does a bunch of

analysis of which servers are most available, and

if there's resources to do this thing, and meets all the

requirements, essentially, including stuff like taints that

we'll learn about later.

But, none of that stuff really pertains to the situation

because we're not setting any limits.

We're not setting any label requirements

or any taints. So, it's just going to schedule those across

the worker nodes as much as possible.

So, it's going to assign one to node 2, and two

to node 1, and spread them out.

But, it's not the scheduler's job to put them

on the server. Its role is to decide where they

go and then to change their configuration and etcd

for where they should go. Are you starting to see how these

different microservice parts work together?

Now, the kubelet is up to bat.

The kubelet is in communication with the API on a regular

basis, and it's looking for work to do.

In this case, it's saying, are there any pods that are

assigned to my node that I am not yet running?

In this case, they both find that yes, indeed.

There are pods waiting to be run that they

don't have listed as running containers on their node.

So, they will change their status in

the database to creating.

Then, they will go and tell the runtime,

in this case Docker, to create a container

and launch the application.

Once the application has successfully started, it will then

update the etcd database to change the status to

running so that anything else needing to know

will be aware that these pods are now running.

If you want to run through this just one more time

to just really nail this down and get this

workflow in your head, this is important.

Because this helps you understand the key differences

of the different parts, right.

The scheduler doesn't actually place things anywhere.

It's simply looking at algorithms, looking

at what's really going on in the nodes and figuring out

where things can run. Then it's just updating etcd.

A lot of these parts are doing a little bit of work and

then updating the records in etcd. The kubelet

is really the one doing the work on each node.

It's creating the containers, running the healthchecks,

making sure the containers are matching what the pod

assignments are in the database.

Now you can see that there is a lot going on the background

even after our command returns that it's

completed.

