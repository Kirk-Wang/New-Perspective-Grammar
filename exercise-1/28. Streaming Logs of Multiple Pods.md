Let's go back to that logs command.

Let's just see a little bit more about dealing with

multiple pods.

In fact, let's try a logs command to see

if we can see the pingpong, which you should still

have running from a couple of lectures ago.

That pingpong now has three replicas.

Let's go see if we can get logs from all of them.

kubectl logs.

We're going to use -l, which means a selector.

We haven't talked about selectors yet, but it's a way

to run commands against more than one

object based on labels.

So, we're going to use the -l, and the label we're going to

look for is run=pingpong, because

these containers are based upon the pingpong

deployment. So, we're going to run this

and we're going to add in --tail like before so we

don't get a huge amount of backlogs.

Then we're going to use the -f, which is the short for

keep following the logs and stay attached to that stream,

right. What you'll notice here is because I know

our ping command only does one ping per second, you'll

probably notice that these are happening

about three a second, which means that we're probably

seeing all three of the pods.

Pretty cool, right?

Let's see what happens when we scale this up even more,

though, because there are limits to this command.

If we jump back and we scale up to eight,

we'll find out that there is a limit, by default,

to the number of pods we can stream the logs from

at the same time.

I'll hit control c there and then kubectl

scale deployment pingpong replicas=8 this

time.

We'll give it a second.

We can actually do a kubectl get

pods to see if we have eight running.

Yeah. We've got our sleep from before there

from the cron job, but we can see we've got all the

pingpong's there. That's what we care about.

We're going to do kubectl logs -l

again, so it's the same command as before.

run=pingpong.

Tail it with one and then

follow. All right, now we're getting an error this

time saying you tried to follow 8 log streams

and you can only do 5.

This is a setting that has changed recently

in Kubernetes configuration.

This is all based around performance.

In the past, we wouldn't even

have this. You can actually see down at the bottom, we have

max log requests. We can use that to increase the limit.

But why is this the case?

Well, pulling logs is a rather strenuous

thing, especially if your apps are dumping

logs en masse.

If you're ever running a proxy or a web server,

and you're capturing every connection into logs, that's

a large amount of logs streaming over the network.

Even if it's on just one machine, that

can be a lot of work for a computer.

It's pulling this from the API.

So, if you think about how this connection is happening,

you're over here typing your kubectl command.

That is being sent to the

API, running on the control plane.

Then that API needs to get the logs

from the pods.

Imagine if you had three,

different nodes all running different pods.

Of course, in our setup here, we've only got it

on one machine probably.

But, if you had three nodes, that could

be happening and each one of these has the kubelet

agent running on it.

So, the API needs to make one connection

to each kubelet.

Then, that kubelet is going to look

at the pod and the container

logs in that pod.

But wait, there's more.

What's technically happening here is it's not just one

connection. For each of these pods, there

are more connections happening.

For each pod, there's a new connection coming out of

kubectl. Then, the API has

one connection to each kubelet.

So, we've got a lot of back and forth happening here,

and this could easily overwhelm your API.

That's important for us to not do.

We don't want to overwhelm the API.

It's the most precious thing in your cluster.

So, you want to protect that, and there's a natural limit

here. You can change that limit, but there's probably

a better way. While we're here, let's just talk about

other shortcomings of the log command.

I've listed them here.

It's a lot of shortcomings.

There's no date timestamp or information about

which Pod sent that particular log line.

If pods change by coming in and out, you know, being

replaced or deleted, they're not changed

in the command. It's only what was working at the time the

command started.

That command got kind of long, like having to write

all that stuff just to get the particular multi-pod

setup from one deployment was a little bit unnecessary.

Luckily, we have

external third-party tools.

The best one for this that I like right now is Stern.

Let's check that next.

