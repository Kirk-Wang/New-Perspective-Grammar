Let's look at what we just did in a more

visual way.

让我们用更直观的方式来看看我们刚刚做了什么。

We were inside this shpod running our cURL in

the top left here. In our case, we're all on the same

node. We'll just make it simple for now.

我们在此 shpod 中，在此处的左上方运行 cURL。
在我们的例子中，我们都在同一节点上。
我们现在将其简化。

Our control plane, when we created that service,

set a bunch of commands down to the kube-proxy.

当我们创建该服务时，我们的控制平面将一系列命令向下设置到 kube-proxy。

The kube-proxy then added

iptable rules to that node

for the clusterIP.

然后，kube-proxy 将 iptable 规则添加到该 clusterIP 的节点。

It used iptables, which we talked about earlier.

它使用 iptables，这是我们之前讨论过的。

This cURL, when we sent it, technically

went through kube-proxy, hit the clusterIP,

and then round robin, one at a time, to each

one of these pods on the backend.

当我们发送此 cURL 时，
从技术上讲，它经过了 kube-proxy，
命中了 clusterIP，
然后一次又一次地循环到后端的每个 pod 中。

It just kept going.

它一直在继续。

That's really it.

就是这样

There is not a lot else there.

那里没有很多其他东西。

There is this hop where it goes through the kube-proxy.

The kube-proxy is acting like the load

balancer. The single IP for the clusterIP

is then essentially natting to

backend pods.

This is known as a userspace proxy mode

for kube-proxy.

All right. So, good job.

You've created your first service.

Job well done.

Let's talk about other options.