Let's look at what we just did in a more

visual way.

让我们用更直观的方式来看看我们刚刚做了什么。

We were inside this shpod running our cURL in

the top left here. In our case, we're all on the same

node. We'll just make it simple for now.

Our control plane, when we created that service,

set a bunch of commands down to the kube-proxy.

The kube-proxy then added

iptable rules to that node

for the clusterIP.

It used iptables, which we talked about earlier.

This cURL, when we sent it, technically

went through kube-proxy, hit the clusterIP,

and then round robin, one at a time, to each

one of these pods on the backend.

It just kept going.

That's really it.

There is not a lot else there.

There is this hop where it goes through the kube-proxy.

The kube-proxy is acting like the load

balancer. The single IP for the clusterIP

is then essentially natting to

backend pods.

This is known as a userspace proxy mode

for kube-proxy.

All right. So, good job.

You've created your first service.

Job well done.

Let's talk about other options.