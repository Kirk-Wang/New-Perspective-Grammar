Now is the time for us to try to scale up our app to

see if we can't improve its DockerCoin mining abilities.

In theory, we're not using all the resources on our

machine. So, why isn't it going faster?

If we're thinking about the performance of an application in something

like this where mining is

typically going as fast as you can possibly make it, that's

our new job. We're now the engineer responsible for making

this thing go fast. If you remember our architecture

diagram from before, we had what looks

like the worker doing a lot of the work here.

It was sending connections out, asking

for data back, then pushing some data up, then

asking for some data back, then storing it in a database.

So, it's probably not our webui because technically, the

webui could go away and we'd still be mining DockerCoins.

It's got to be one of these four things there.

The worker seems to be the one doing most

of the work. I wonder what would happen if we added

more workers. We can always start by just doing

a whole bunch of performance analysis first, but let's just

spin it up.

Let's just see what happens when we add more. It's not hard. It's

a couple of commands here.

Let's open two terminals at

the same time. However you want to do that.

We're going to watch while

we're doing something on a third one.

We're going technically have three, different terminals

open at once.

All right. You see I've got three commands here.

Two that are watching the pods and deployment so we

can see those happening and changing in real time.

Then we're going to scale.

We're going to use that scale command we used earlier with

replicas of two.

We're going to run three commands and three terminals,

and the first two, the pods and the get deployments.

Those two commands up top there, we'll just be watching.

We'll be able to see the changes happening in real time.

I'll just do those in two, separate windows.

Then in the third window, we're going to do a scale

and scale our worker up to 2.

It'd be simple enough.

Maybe we'll get some better performance.

On my left, I have the scale up command.

On my right, I have the pods in the top right.

You can see we have one pod for each, 1 of 1.

That's what the ready column means.

Then down at the bottom, we have the deployments, and we

have one ReplicaSet for each one of those.

All right.

On the left, I'm going to hit replicas 2.

We're seeing now the very bottom.

You can see the worker 2/2 down at the bottom

on the deployment.

Then you can see a separate container coming up,

1/1 for the workers.

So, that that last four lines is it's spinning up

basically the logs of that history

on pending, which is getting the container ready

to start and then actually creating

it, and then starting it to the running command.

If you've ever seen something sit in the pending command

for a while, in the pending state, that's usually because

it's downloading the image. So, if you have large images,

the pending...part of that pending is the image download.

If you're not on super fast links, then that will sit there

a while. So, don't worry about it if it sits there for a

few seconds. Let's go back to our browser, and you'll see

that we should be showing a

double performance improvement. We've got eight.

So, we've gone from four to eight, which

seems like a linear translation. We're going from one

container, two containers. We're going from four to eight

mines per second, approximately.

So, maybe we're onto something. Maybe let's just keep

adding more workers. In theory, our next guess is, OK,

maybe if I have three workers, I'll get triple the

performance. Let's just go back to that command line, and

we're just going to hit the up arrow and change the

replicas to three. Maybe we'll

go back to the browser, and we'll see if it goes to triple

that speed. Hey, look at that.

It's now triple.

We're somewhere around 12.

Remember, there's the 12 or nothing kind of approach,

but we're approaching 12, which seems like it's triple the

performance. So, good news here.

We're going to be DockerCoin rich.

We're just going to scale this thing as

much as our resources will allow, and this is going to

solve the problem. Easy day. We can all go home.

But, something's going to happen here.

I'm not going to give it away.

So, let's go back to the command line, and let's try 10.

Let's just see if it's that easy.

It could be that easy, right?

Because applications are always easy.

Why not? We're spinning up 10 workers.

You can see on the right, down at the very bottom there,

we've got the workers now saying it's at 10 of

10, right.

Go back to our browser and let's see what we're seeing over

there.

Huh. It almost seems like it's gotten slower.

It looks like we're steady at 10.

Which is a real bummer.

Thought we had this licked.

All right. Let's go back to our imaginary

problem here and let's see.

OK. Well, we obviously can't get anything

with the worker. I mean, we could probably give it 20, but

there's no sign that it's going to get any better.

So, now we've hit some sort of bottleneck in worker,

but maybe it's something else is the bottleneck.

Maybe workers already working or exceeding the performance

of some other part of the application. Again, we could do

more performance analytics, but let's just try

a couple of basic things.