Now is the time for us to try to scale up our app to

see if we can't improve its DockerCoin mining abilities.

现在是时候扩大我们的应用程序，
看看我们是否可以提高其 DockerCoin 挖掘能力。

In theory, we're not using all the resources on our

machine. So, why isn't it going faster?

理论上，我们没有使用机器上的所有资源。那么，为什么速度没有变快呢?

If we're thinking about the performance of an application in something

like this where mining is

typically going as fast as you can possibly make it, that's

如果我们考虑应用程序的性能，
在这样的情况下，
挖掘通常尽可能快，这是我们的新工作。

our new job. We're now the engineer responsible for making

this thing go fast. If you remember our architecture

diagram from before, we had what looks

like the worker doing a lot of the work here.

我们的新工作。 
现在，我们是负责使此事情快速发展的工程师。 
如果您还记得我们以前的体系结构图，
那么看起来工人在这里做了很多工作。

It was sending connections out, asking

for data back, then pushing some data up, then

asking for some data back, then storing it in a database.

它发送连接，请求返回数据，
然后向上推送一些数据，
然后请求返回一些数据，
然后将其存储在数据库中。

So, it's probably not our webui because technically, the

webui could go away and we'd still be mining DockerCoins.

所以，这可能不是我们的 webui，因为从技术上讲，
webui 可能会消失，我们仍然在挖掘 DockerCoins。

It's got to be one of these four things there.

它必须是这四个中的一个。
* be one of 成为......之一

The worker seems to be the one doing most

of the work. I wonder what would happen if we added

这个 worker 似乎是做大部分工作的人。
我想知道如果我们增加 worker 会发生什么。

more workers. We can always start by just doing

a whole bunch of performance analysis first, but let's just

spin it up.

我们总是可以先做一系列的性能分析，但是让我们先把它展开。

Let's just see what happens when we add more. It's not hard. It's

a couple of commands here.

让我们看看当我们添加更多的时候会发生什么。它并不困难。这里有几个命令。

Let's open two terminals at

the same time. However you want to do that.

让我们同时打开两个终端。你想怎么做就怎么做。
* at the same time 同时; 然而;不过

We're going to watch while

we're doing something on a third one.

我们要看第三个视频。

We're going technically have three, different terminals

open at once.

从技术上讲，我们要同时打开三个不同的终端。
* at once 马上，立刻

All right. You see I've got three commands here.

好吧。这里有三个命令。

Two that are watching the pods and deployment so we

can see those happening and changing in real time.

两个正在观察 pods 和 deployment，
这样我们就能实时看到它们的发生和变化。

Then we're going to scale.

然后我们将进行缩放。

We're going to use that scale command we used earlier with

replicas of two.

我们将使用之前在两个副本中使用的 scale 命令。

We're going to run three commands and three terminals,

and the first two, the pods and the get deployments.

我们将运行三个命令和三个终端，前两个是 pods 和 get deployments。

Those two commands up top there, we'll just be watching.

上面的这两个指令，我们将拭目以待。

We'll be able to see the changes happening in real time.

我们将能够看到实时发生的变化。

I'll just do those in two, separate windows.

我将在两个单独的窗口中进行操作。

Then in the third window, we're going to do a scale

and scale our worker up to 2.

然后在第三个窗口中，我们将进行缩放，并将我们的工作人员扩展到 2。

It'd be simple enough.

这很简单。

Maybe we'll get some better performance.

也许我们会得到更好的性能。

On my left, I have the scale up command.

在我的左边，我有扩大规模命令。

On my right, I have the pods in the top right.

在我的右边，我的 pods 在右上角。

You can see we have one pod for each, 1 of 1.

你可以看到我们各自有一个 pod，1/1。

That's what the ready column means.

这就是 ready 列的意思。

Then down at the bottom, we have the deployments, and we

have one ReplicaSet for each one of those.

在底部，我们有部署，每个部署都有一个副本集。

All right.

好吧。

On the left, I'm going to hit replicas 2.

在左边，我要打 replicas 2。

We're seeing now the very bottom.

我们现在看到的是最底部。

You can see the worker 2/2 down at the bottom

on the deployment.

您可以在 deployment 的底部看到 worker 2/2。

Then you can see a separate container coming up,

1/1 for the workers.

然后您可以看到一个单独的容器，workers 的容器为 1/1。

So, that that last four lines is it's spinning up

basically the logs of that history

on pending, which is getting the container ready

to start and then actually creating

it, and then starting it to the running command.

因此，
最后四行是它基本上是在等待处理中收集该历史记录的日志，
这使容器准备好启动，
然后实际创建它，
然后将其启动到正在运行的命令。

If you've ever seen something sit in the pending command

for a while, in the pending state, that's usually because

it's downloading the image. So, if you have large images,

the pending...part of that pending is the image download.

如果您曾经看到某个东西在 pending 命令中停留了一段时间，
处于 pending 状态，这通常是因为它正在下载镜像。
所以，如果你有大的镜像，
pending…pending 其中一部分是镜像下载。

If you're not on super fast links, then that will sit there

a while. So, don't worry about it if it sits there for a

few seconds. Let's go back to our browser, and you'll see

that we should be showing a

double performance improvement. We've got eight.

如果你不是在超快的连接，然后将坐在那里一段时间。
所以，如果它在那里停留了几秒钟，不用担心。

So, we've gone from four to eight, which

seems like a linear translation. We're going from one

container, two containers. We're going from four to eight

mines per second, approximately.

So, maybe we're onto something. Maybe let's just keep

adding more workers. In theory, our next guess is, OK,

maybe if I have three workers, I'll get triple the

performance. Let's just go back to that command line, and

we're just going to hit the up arrow and change the

replicas to three. Maybe we'll

go back to the browser, and we'll see if it goes to triple

that speed. Hey, look at that.

It's now triple.

We're somewhere around 12.

Remember, there's the 12 or nothing kind of approach,

but we're approaching 12, which seems like it's triple the

performance. So, good news here.

We're going to be DockerCoin rich.

We're just going to scale this thing as

much as our resources will allow, and this is going to

solve the problem. Easy day. We can all go home.

But, something's going to happen here.

I'm not going to give it away.

So, let's go back to the command line, and let's try 10.

Let's just see if it's that easy.

It could be that easy, right?

Because applications are always easy.

Why not? We're spinning up 10 workers.

You can see on the right, down at the very bottom there,

we've got the workers now saying it's at 10 of

10, right.

Go back to our browser and let's see what we're seeing over

there.

Huh. It almost seems like it's gotten slower.

It looks like we're steady at 10.

Which is a real bummer.

Thought we had this licked.

All right. Let's go back to our imaginary

problem here and let's see.

OK. Well, we obviously can't get anything

with the worker. I mean, we could probably give it 20, but

there's no sign that it's going to get any better.

So, now we've hit some sort of bottleneck in worker,

but maybe it's something else is the bottleneck.

Maybe workers already working or exceeding the performance

of some other part of the application. Again, we could do

more performance analytics, but let's just try

a couple of basic things.