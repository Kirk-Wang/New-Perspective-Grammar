Kubernetes architecture.

That is specific to both the logical

parts and the physical parts.

But, in this video, we are only going to talk about really

the physical parts. The applications that have to run for

Kubernetes to work and then what goes on each node.

Let's look at a simple Kubernetes diagram.

That's a joke.

That's not a simple diagram at all.

In fact, that is a real Kubernetes architecture, but

we're not going to get there for a while.

That's a pretty complex one that includes iSCSI and

redundant storage, backends and a whole bunch of other

stuff. So, no.

This is a more realistic diagram to start off with.

What this is showing is largely

a physical diagram that's showing the different

pieces of actual programs and infrastructure.

But, it's also a little bit logical.

So, let's lay it out.

What we have here in the middle are three nodes.

On the left, you see the master, which

is in control of the environment, also called the control

plane. We'll talk more about all this throughout the

course. Then, those nodes

are all connected to a physical infrastructure.

Then they have on the top

maybe a logical network or some type of

physical, or encapsulated, network where

everything is talking. So, that all technically could be

over a single NIC across your machines, or you could have

many NICs. It doesn't matter.

You can splice it up how you want.

What we want to focus on here are the required

parts.

Let's take a look a little closer at this

diagram to see how it lays

out.

On the left, let's focus on the master.

Also really known as the control plane.

This is the stuff that controls

the cluster, whether it's a single machine or a thousand

nodes. It has four

required parts.

Down here at the bottom, we have the database, the etcd.

That is a key value store

that contains all the information from configuring

the environment to how your apps are supposed to run.

It's basically THE database that we need to take

care of. We need to back it up.

We'll talk a lot more about that later.

The controller manager, scheduler and API

are all separate programs that need

to run on one or more master nodes.

The API server we talk a lot about.

It is the heart and soul of Kubernetes

where everything is talking through it.

That includes agents on the nodes,

like this kubelet agent here.

That's sort of the node that controls the Docker

Engine on each physical machine.

For every OS that's running Docker in this

case. We're just talking about Docker.

We'll talk more about other container runtimes

later. That's running containers,

right. So, we got these four blocks here.

Those are maybe your app.

They're all running in individual containers.

We have the host operating system.

In this case, we're really largely talking about Linux, but

it could be Windows because it operates the same way.

Then, down here at the bottom is either the hardware, or

the virtual machine, that you're running it on.

The kubelet is the agent that talks

back to the API. We'll talk more about that in a minute.

The API manages the scheduler

and the controller manager.

Those two parts work in concert with the API

to basically control all the parts, right.

It tells which nodes to run which containers.

It takes orders from either your command

lines or other remote things talking to the

API. So, the API is both an inbound

and an outbound. It actually talks to things back and

forth. You'll notice down here on the nodes, we also have

this part called the kube-proxy.

The kube-proxy is all about networking.

It takes orders from the kubelet agent

and it controls the networking configuration

on the host.

So, it might issue out the IP addresses.

It might control the network parameters and settings.

We'll talk a lot more about that as well.

You see up here at the top, we have something called an

overlay network.

That's really all about the networking

driver. This is one of the parts of Kubernetes that's

pretty unique. Coming out-of-the-box, it

doesn't have a networking component to

it. You actually have to decide which one you want to use.

We'll go through some of the options later as well.

These are the parts that really

make it up. Each node, you can have as many of

those nodes as you want.

Then, this master over here on the left, well,

we can have one or more of those.

All of this can all be running on one big

node. I know it's starting to look like a scribble at this

point. But, all of this stuff is running.

You could run it all in a single node.

That's what we're going to do today.

We're going to back this all up,

and we're essentially going to have our little lab

node that we're going to learn on.

It's going to run all these different components on

the same VM or physical machine.

All right. So, we're going to combine the API

service scheduler, controller manager, etcd

and the kubelet and the kube-proxy

to a single machine.

The other thing that's not on here, that we'll talk about

later, is CoreDNS, which is

technically optional.

It's going to run on your host over here.

That's technically optional, but we're really going to need

it.

You're probably going to need some form of DNS to run

what we call Services in your orchestrator.

So, we're always going to end up having that.

When you use Docker Desktop or any of the Enterprise

Humanity Solutions, they're all going to have CoreDNS in

them. So, let's just assume that that's in there as well.

